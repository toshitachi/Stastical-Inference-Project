md + c(-1,1)*qt(.975,18)*sp*sqrt(1/5)
t.test(g2,g1,paired=FALSE,var.equal=TRUE)
t.test(g2,g1,paired=FALSE,var.equal=TRUE)$conf
t.test(g2,g1,paired=TRUE,var.equal=TRUE)$conf
t.test(g2,g1,paired=TRUE)$conf
num<-sqrt((15.34^2/8+18.23^2/21))
num<-((15.34^2/8+18.23^2/21))^2
den<-(15.34/8^2/7+18.23/21^2/20)
den<-15.34^4/8^2/7+18.23^4/21^2/20
mydf<-num/den
qt(0.975,mydf)
132.86-127.44+c(-1,1)*qt(0.975,mydf)*sqrt(15.34^2/8+18.23^2/21)
32/sqrt(100)
10/sqrt(100)
(32-30)/(10/sqrt(100))
(32-30)/(10/sqrt(16))
15
qt(0.95)
qt(0.95,df)
skip()
dim(fs)
t.test(fs,1078*2-1)
t.test(fs)
t.test(fs$sheight-fs$fheight)
11.7885
| * sd(fs$sheight-fs$fheight)/sqrt(1078)
11.7885 * sd(fs$sheight-fs$fheight)/sqrt(1078)
mybin
0.00390625
0.035
skip()
pt(q=2.5,df=15,lower.tail=FALSE)
qnorm(0.95)
qnorm(0.99)
pnorm(2)
pnorm(2,lower.tail=FALSE)
mybin
pbinorm(6,size=8,prob=0.5,lower.tail=FALSE)
pbinom(6,size=8,prob=0.5,lower.tail=FALSE)
pbinom(7,size=8,prob=0.5,lower.tail=TRUE)
ppois(9,5,lower.tail=FALSE)
qnorm(0.95)
qnorm(0.975)
##Statical Inference-Quiz3##
##Q1##
n <- 9
1100 + c(-1, 1) * qt(.975, n - 1) * 30 / sqrt(n)
##Q2##
n <- 9
(sd <- 2 * sqrt(n) / qt(.975, n - 1))
##Q4##
old.mean <- 5
old.var <- 0.68
old.n <- 10
new.mean <- 3
new.var <- 0.60
new.n <- 10
alpha <- (1 - .95)
t <- qt(1 - alpha / 2, old.n + new.n - 2)
##Statical Inference-Quiz3##
##Q1##
n <- 9
1100 + c(-1, 1) * qt(.975, n - 1) * 30 / sqrt(n)
##Q2##
n <- 9
sd <- 2 * sqrt(n) / qt(.975, n - 1)
##Q4##
old.mean <- 5
old.var <- 0.68
old.n <- 10
new.mean <- 3
new.var <- 0.60
new.n <- 10
alpha <- (1 - .95)
t <- qt(1 - alpha / 2, old.n + new.n - 2)
##Statical Inference-Quiz3##
##Q1##
n <- 9
1100 + c(-1, 1) * qt(.975, n - 1) * 30 / sqrt(n)
##Q2##
n <- 9
sd <- 2 * sqrt(n) / qt(.975, n - 1)
sd
##Q4##
old.mean <- 5
old.var <- 0.68
old.n <- 10
new.mean <- 3
new.var <- 0.60
new.n <- 10
alpha <- (1 - .95)
t <- qt(1 - alpha / 2, old.n + new.n - 2)
t
n <- 9
sd <- 2 * sqrt(n) / qt(.975, n - 1)
-2 + c(-1, 1) * qt(.975, n - 1) * sd / sqrt(n)
old.mean <- 5
old.var <- 0.68
old.n <- 10
new.mean <- 3
new.var <- 0.60
new.n <- 10
alpha <- (1 - .95)
t <- qt(1 - alpha / 2, old.n + new.n - 2)
t
##Statical Inference-Quiz3##
##Q1##
n <- 9
m<-1100
sd<-30
m + c(-1, 1) * qt(.975, n - 1) * sd / sqrt(n)
##Q2##
n <- 9
m<--2
sd <- m * sqrt(n) / qt(.975, n - 1)
##Q4##
old.mean <- 5
old.var <- 0.68
old.n <- 10
new.mean <- 3
new.var <- 0.60
new.n <- 10
alpha <- (1 - .95)
t <- qt(1 - alpha / 2, old.n + new.n - 2)
t
sp <- sqrt(((old.n - 1) * old.var + (new.n - 1) * new.var) / (old.n + new.n - 2))
(new.mean - old.mean) + c(-1, 1) * t * sp * sqrt(1 / old.n + 1 / new.n)
##Q6##
old.mean <- 6
old.sd <- 2
old.n <- 100
old.var <- old.sd^2
old.var_n <- old.var / old.n
new.mean <- 4
new.sd <- 0.5
new.n <- 100
new.var <- new.sd^2
new.var_n <- new.var / new.n
df <- (old.var_n + new.var_n) ^ 2 /(old.var_n^2 / (old.n - 1) + new.var_n^2 / (new.n - 1))
t <- qt(1 - alpha / 2, df)
(old.mean - new.mean) + c(-1, 1) * t * sqrt(old.var_n + new.var_n)
##Statical Inference-Quiz3##
##Q1##
n <- 9
m<-1100
sd<-30
m + c(-1, 1) * qt(.975, n - 1) * sd / sqrt(n)
##Q2##
n <- 9
m<--2
sd <- m * sqrt(n) / qt(.975, n - 1)
##Q4##
old.mean <- 5
old.var <- 0.68
old.n <- 10
new.mean <- 3
new.var <- 0.60
new.n <- 10
alpha <- (1 - .95)
t <- qt(1 - alpha / 2, old.n + new.n - 2)
t
sp <- sqrt(((old.n - 1) * old.var + (new.n - 1) * new.var) / (old.n + new.n - 2))
(new.mean - old.mean) + c(-1, 1) * t * sp * sqrt(1 / old.n + 1 / new.n)
##Q6##
old.mean <- 6
old.sd <- 2
old.n <- 100
old.var <- old.sd^2
old.var_n <- old.var / old.n
new.mean <- 4
new.sd <- 0.5
new.n <- 100
new.var <- new.sd^2
new.var_n <- new.var / new.n
df <- (old.var_n + new.var_n) ^ 2 /(old.var_n^2 / (old.n - 1) + new.var_n^2 / (new.n - 1))
t <- qt(1 - alpha / 2, df)
(old.mean - new.mean) + c(-1, 1) * t * sqrt(old.var_n + new.var_n)
##Q7##
n_x<-9
n_y<-9
bar_x<--3
bar_y<-1
s_x<-1.5
s_y<-1.8
α<-0.1
t<-qt(α/2,n_x+n_y-2)
sp<-sqrt(((n_x-1)*s_x^2+(n_y-1)*s_y^2)/(n_x+n_y-2))
(bar_x-bar_y)+c(-1,1)*t*sp*(sqrt(1/n_x+1/n_y))
subject <- c(1,2,3,4,5)
baseline <- c(140,138,150,148,135)
week2 <- c(132,135,151,146,130)
examinations <- data.frame(subject, baseline, week2) ## Create Dataframe
examinations
test <- t.test(x = examinations$baseline, y = examinations$week2, alt = "two.sided", paired = TRUE)
pval <- test$p.value
pval
n <- 9
μ <- 1100
σ <- 30
quantile = 0.975 # is 95% with 2.5% on both sides of the range
confidenceInterval = μ + c(-1, 1) * qt(quantile, df=n-1) * σ / sqrt(n)
confidenceInterval
n <- 4
x <- 3
test <- binom.test(x=x, n=n, alt="greater")
test$p.value
?binom.test
rate <- 1/100
errors <- 10
days <- 1787
test <-  poisson.test(errors, T = days, r = rate, alt="less")
test$p.value,2
test$p.value
n_y <- 9 # subjects treated
n_x <- 9 # subjects placebo
σ_y <- 1.5# kg/m2 std.dev. treated
σ_x <- 1.8# kg/m2 std.dev. placebo
μ_y <- -3#  kg/m2 average difference treated
μ_x <- 1#  kg/m2 average difference placebo
# calculate pooled standard deviation
σ_p <- (((n_x - 1) * σ_x^2 + (n_y - 1) * σ_y^2)/(n_x + n_y - 2))
pval <- pt((μ_y - μ_x) / (σ_p * (1 / n_x + 1 / n_y)^.5), df=n_y + n_x -2)
pval
n <- 100 #subject
μ <- 0.01# m^3 brain volume loss mean
σ <- 0.04# m^3 brain volume loss std. dev.
p <- 0.05 # sign level
pow <- power.t.test(n=n, delta=μ, sd=σ , sig.level=p, type="one.sample", alt="one.sided")$power
pow
μ <- 0.01# m^3 brain volume loss mean
σ <- 0.04# m^3 brain volume loss std. dev.
p <- 0.05 # sign level
pow <- 0.9 #power
n <- power.t.test(power=pow, delta=μ, sd=σ , sig.level=p, type="one.sample", alt="one.sided")$n
ceiling(n/10)*10
?binomial
?binom.test
?poisson.test
##Analytical Inference Quiz4##
##Q1##
# t-test on the paired subjects with 2sides
subject <- c(1,2,3,4,5)
baseline <- c(140,138,150,148,135)
week2 <- c(132,135,151,146,130)
examinations <- data.frame(subject, baseline, week2) # Create Dataframe
examinations
test <- t.test(x = examinations$baseline, y = examinations$week2, alt = "two.sided", paired = TRUE)
pval <- test$p.value # extract only p-value
pval
##Q2##
# to get confidental interval
#by using "μ + c(-1, 1) * qt(quantile, df=n-1) * σ / sqrt(n)"
n <- 9
μ <- 1100
σ <- 30
quantile = 0.975 # is 95% with 2.5% on both sides of the range
confidenceInterval = μ + c(-1, 1) * qt(quantile, df=n-1) * σ / sqrt(n)
confidenceInterval
##Q3##
# to get p-values by using "binom.test(x, n, p = 0.5,
# alternative = c("two.sided", "less", "greater"),conf.level = 0.95)"
n <- 4
x <- 3
test <- binom.test(x=x, n=n, alt="greater")
test$p.value
##Q4##
#poisson.test(x, T = 1, r = 1,
#alternative = c("two.sided", "less", "greater"),conf.level = 0.95)
rate <- 1/100
errors <- 10
days <- 1787
test <-  poisson.test(errors, T = days, r = rate, alt="less")
test$p.value
##Q5##
# compare two groups,one controlled and another uncontrolled
# by calculating p-value for pooled sd.
n_y <- 9 # subjects treated
n_x <- 9 # subjects placebo
σ_y <- 1.5# kg/m2 std.dev. treated
σ_x <- 1.8# kg/m2 std.dev. placebo
μ_y <- -3#  kg/m2 average difference treated
μ_x <- 1#  kg/m2 average difference placebo
# calculate pooled standard deviation#
σ_p <- (((n_x - 1) * σ_x^2 + (n_y - 1) * σ_y^2)/(n_x + n_y - 2))
pval <- pt((μ_y - μ_x) / (σ_p * (1 / n_x + 1 / n_y)^.5), df=n_y + n_x -2)
pval
##Q7##
# calculation of power by power.t.test##
n <- 100 #subject
μ <- 0.01# m^3 brain volume loss mean
σ <- 0.04# m^3 brain volume loss std. dev.
p <- 0.05 # sign level
pow <- power.t.test(n=n, delta=μ, sd=σ , sig.level=p, type="one.sample", alt="one.sided")$power
pow
##Q8##
# calculation of necessary sample size given power by power.t.test#
μ <- 0.01# m^3 brain volume loss mean
σ <- 0.04# m^3 brain volume loss std. dev.
p <- 0.05 # sign level
pow <- 0.9 #power
n <- power.t.test(power=pow, delta=μ, sd=σ , sig.level=p, type="one.sample", alt="one.sided")$n
ceiling(n/10)*10
library(swirl)
swirl()
muplot(34)
myplot(34)
myplot(33.3)
myplot(30)
myplot(28)
a<-qnorm(.95)
z<-qnorm(.95)
play()
pnorm()
?pmorm()
?pnorm
nxt()
pnorm(z,mean=30,sd=1,lower.tail=FALSE)
pnorm(30+z,mean=30,sd=1,lower.tail=FALSE)
pnorm(30+z,mean=32,sd=1,lower.tail=FALSE)
pnorm(quqntile(30+z),mean=32,sd=1,lower.tail=FALSE)
pnorm(quantile(30+z),mean=32,sd=1,lower.tail=FALSE)
pnorm(30+z,mean=32,sd=1,lower.tail=FALSE)
pnorm(30+z*2,mean=32,sd=2,lower.tail=FALSE)
power.t,test(n=16,delta=2/4,sd=1,type="one.sample",alt="one.sided")$power
power.t.test(n=16,delta=2/4,sd=1,type="one.sample",alt="one.sided")$power
power.t.test(n=16,delta=2/2,sd=1,type="one.sample",alt="one.sided")$power
power.t.test(n=16,delta=2,sd=1,type="one.sample",alt="one.sided")$power
power.t.test(n=16,delta=2,sd=4,type="one.sample",alt="one.sided")$power
power.t.test(n=16,delta=100,sd=200,type="one.sample",alt="one.sided")$power
power.t.test(power=.8,delta=2/4,sd=1,type="one.sample",alt="one.sided")$n
power.t.test(power=.8,delta=2,sd=4,type="one.sample",alt="one.sided")$n
power.t.test(power=.8,delta=100,sd=200,type="one.sample",alt="one.sided")$n
power.t.test(power=.8,n=26,sd=1,type="one.sample",alt="one.sided")$delta
power.t.test(power=.8,n=27,sd=1,type="one.sample",alt="one.sided")$delta
head(pValues)
skip()
p.adjust(pValues,method="bonferroni")
sum(p.adjust(pValues,method="bonferroni") < 0.05)
sum(p.adjust(pValues,method="BH") < 0.05)
tail(trueStatus)
table(pValues<.05, trueStatus)
table(pValues2<.05, trueStatus)
24/(476+24)
table(p.adjust(pValues,method="bonferroni")<.05, trueStatus)
table(p.adjust(pValues2,method="bonferroni")<.05, trueStatus)
table(p.adjust(pValues2,method="BH")<.05, trueStatus)
1*1/6+2*1/6+3*1/6+4*1/6+5*1/6+6*1/6
print(g2)
head(sh)
length(nh)
nh
median(resampledMedians)
median(sh)
sam<-sample(fh,nh*B,replace=TRUE)
resam<-matrix(sam)
resam<-matrix(sam, B, nh)
meds<-apply(resam,1,median)
median(fh)-meds
median(fh)-median(meds)
sd(meds)
sd(resampledMedians)
quantile(resampledMedians, c(.025,0.975))
quantile(meds, c(.025,0.975))
dim(InsectSprays)
names(InsectSprays)
range(Bdata$count)
range(Cdata$count)
BCcounts
skip()
testStat
obs<-testStat(BCcounts,group)
obs
mean(Bdata$count-Cdata$count)
sample(group)
perms<-sapply(1:10000,function(i) testStat(BCcounts, sample(group)))
mean("perms">"obs")
mean(perms>obs)
testStat(DEcounts,group)
perms <- sapply(1 : 10000, function(i) testStat(DEcounts,
| sample(group)))
perms <- sapply(1 : 10000, function(i) testStat(DEcounts,sample(group)))
getwd()
?markdownToHTML
??markdownTOHRML
require(knitr)
require(ggplot2)
require(markdown)
require(markdownToHTML)
ianstall(markdownToHTML)
install.packages("markdownToHTML")
setwd("C:/Users/Tachibana/Documents/GitHub/Stastical Infrence")
require(knitr)
require(ggplot2)
require(markdown)
set.seed=(1)
no_sim <- 1000
lambda <- 0.2
n <- 40
sim_matrix <- matrix(rexp(no_sim * n, rate=lambda), no_sim, n)
sim_mean <- rowMeans(sim_matrix)
mean_data <- mean(sim_mean)
theory_mean <- 1/lambda
actual_sd<-sd(sim_mean)
actual_var <- var(sim_mean)
theory_sd<-sd(sim_mean)
theory_var <- (1/lambda)^2
plotdata <- data.frame(sim_mean)
g<-ggplot(plotdata, aes(x =sim_mean))
g<-g+geom_histogram(binwidth = lambda,fill="green",color="black",aes(y = ..density..))
g<-g+labs(title="Density of 40 Numbers from Exponential Distribution", x="Mean of 40 Selections", y="Density")
g<-g+geom_vline(xintercept=mean_data,size=1.0, color="black")
g<-g+stat_function(fun=dnorm,args=list(mean=mean_data, sd=sqrt(actual_sd),color = "blue", size = 1.0))
g<-g+geom_vline(xintercept=theory_mean,size=1.0,color="yellow",linetype = "longdash")
g<-g+stat_function(fun=dnorm,args=list(mean=theory_mean, sd=theory_sd,color = "red", size = 1.0))
g
?stat_function
theory_sd<-sd(1/lambda)
plotdata <- data.frame(sim_mean)
g<-ggplot(plotdata, aes(x =sim_mean))
g<-g+geom_histogram(binwidth = lambda,fill="green",color="black",aes(y = ..density..))
g<-g+labs(title="Density of 40 Numbers from Exponential Distribution", x="Mean of 40 Selections", y="Density")
g<-g+geom_vline(xintercept=mean_data,size=1.0, color="black")
g<-g+stat_function(fun=dnorm,args=list(mean=mean_data, sd=actual_sd,color = "blue", size = 1.0))
g<-g+geom_vline(xintercept=theory_mean,size=1.0,color="yellow",linetype = "longdash")
g<-g+stat_function(fun=dnorm,args=list(mean=theory_mean, sd=theory_sd,color = "red", size = 1.0))
g
sim_matrix <- matrix(rexp(no_sim * n, rate=lambda), no_sim, n)
sim_mean <- rowMeans(sim_matrix)
actual_mean <- mean(sim_mean)
theory_mean <- 1/lambda
actual_sd<-sd(sim_mean)
actual_var <- var(sim_mean)
theory_sd<-sd(1/lamda)
theory_var <- (1/lambda)^2
theory_sd<-sd(1/lambda)
plotdata <- data.frame(sim_mean)
g<-ggplot(plotdata, aes(x =sim_mean))
g<-g+geom_histogram(binwidth = lambda,fill="green",color="black",aes(y = ..density..))
g<-g+labs(title="Density of 40 Numbers from Exponential Distribution", x="Mean of 40 Selections", y="Density")
g<-g+geom_vline(xintercept=mean_data,size=1.0, color="black")
g<-g+stat_function(fun=dnorm,args=list(mean=actual_mean, sd=actual_sd,color = "blue", size = 1.0))
g<-g+geom_vline(xintercept=theory_mean,size=1.0,color="yellow",linetype = "longdash")
g<-g+stat_function(fun=dnorm,args=list(mean=theory_mean, sd=theory_sd,color = "red", size = 1.0))
g
g<-ggplot(plotdata, aes(x =sim_mean))
g<-g+geom_histogram(binwidth = lambda,fill="green",color="black",aes(y = ..density..))
g<-g+labs(title="Density of 40 Numbers from Exponential Distribution", x="Mean of 40 Selections", y="Density")
g<-g+geom_vline(xintercept=mean_data,size=1.0, color="black")
g<-g+stat_function(fun=dnorm,args=list(mean=actual_mean, sd=actual_sd),color = "blue", size = 1.0)
g<-g+geom_vline(xintercept=theory_mean,size=1.0,color="yellow",linetype = "longdash")
g<-g+stat_function(fun=dnorm,args=list(mean=theory_mean, sd=theory_sd),color = "red", size = 1.0)
g
actual_mean
theory_mean
actual_sd
thoery_sd
theory_sd
theory_sd<-1/lambda
g<-ggplot(plotdata, aes(x =sim_mean))
g<-g+geom_histogram(binwidth = lambda,fill="green",color="black",aes(y = ..density..))
g<-g+labs(title="Density of 40 Numbers from Exponential Distribution", x="Mean of 40 Selections", y="Density")
g<-g+geom_vline(xintercept=mean_data,size=1.0, color="black")
g<-g+stat_function(fun=dnorm,args=list(mean=actual_mean, sd=actual_sd),color = "blue", size = 1.0)
g<-g+geom_vline(xintercept=theory_mean,size=1.0,color="yellow",linetype = "longdash")
g<-g+stat_function(fun=dnorm,args=list(mean=theory_mean, sd=theory_sd),color = "red", size = 1.0)
g
actual_mean
theory_mean
actual_sd
theory_sd
actual_sd<-sd(sim_mean)
actual_var <- var(sim_mean)
theory_sd<-1/lambda*(1/sqrt(n))
theory_var <- theory_sd^2
plotdata <- data.frame(sim_mean)
g<-ggplot(plotdata, aes(x =sim_mean))
g<-g+geom_histogram(binwidth = lambda,fill="green",color="black",aes(y = ..density..))
g<-g+labs(title="Density of 40 Numbers from Exponential Distribution", x="Mean of 40 Selections", y="Density")
g<-g+geom_vline(xintercept=mean_data,size=1.0, color="black")
g<-g+stat_function(fun=dnorm,args=list(mean=actual_mean, sd=actual_sd),color = "blue", size = 1.0)
g<-g+geom_vline(xintercept=theory_mean,size=1.0,color="yellow",linetype = "longdash")
g<-g+stat_function(fun=dnorm,args=list(mean=theory_mean, sd=theory_sd),color = "red", size = 1.0)
g
sample_mean <- mean(sim_mean)
theory_mean <- 1/lambda
sample_mean
theory_mean
sample_sd<-sd(sim_mean)
sample_var <- var(sim_mean)
theory_sd<-1/lambda*(1/sqrt(n))
theory_var <- theory_sd^2
plotdata <- data.frame(sim_mean)
g<-ggplot(plotdata, aes(x =sim_mean))
g<-g+geom_histogram(binwidth = lambda,fill="green",color="black",aes(y = ..density..))
g<-g+labs(title="Density of 40 Numbers from Exponential Distribution", x="Mean of 40 Selections", y="Density")
g<-g+geom_vline(xintercept=mean_data,size=1.0, color="black")
g<-g+stat_function(fun=dnorm,args=list(mean=sample_mean, sd=sample_sd),color = "blue", size = 1.0)
g<-g+geom_vline(xintercept=theory_mean,size=1.0,color="yellow",linetype = "longdash")
g<-g+stat_function(fun=dnorm,args=list(mean=theory_mean, sd=theory_sd),color = "red", size = 1.0)
g
sample_sd
theory_sd
knit("Report_Stastical_Infrence_Project_Part1.Rmd")
markdownToHTML('Report_Stastical_Infrence_Project_Part1.md', 'Report_Stastical_Infrence_Project_Part1.html', options=c("use_xhml"))
system("pandoc -s Report_Stastical_Infrence_Project_Part1.html -o Report_Stastical_Infrence_Project_Part1.pdf")
system("pandoc -s Report_Stastical_Infrence_Project_Part1.html -o Report_Stastical_Infrence_Project_Part1.pdf")
?system
pondec
pandec
pandoc
?pandoc
system("pandoc -s Report_Stastical_Infrence_Project_Part1.html -o Report_Stastical_Infrence_Project_Part1.pdf")
